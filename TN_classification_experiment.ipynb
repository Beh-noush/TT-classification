{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TN-classification-experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3KUlYpbPwqlk",
        "650DaIwzyNl9",
        "A0kOpOEKTmA7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beh-noush/TT-classification/blob/main/TN_classification_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****We will adjust this code for the case of multi-class classification. That is, the function 'make_tensor' wont use the command 'tl.tt_to_tensor' or 'tl.cp_to_tensor' any more. "
      ],
      "metadata": {
        "id": "kXDrc8CEu3o4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHNpDC3HFpPq",
        "outputId": "cc4da3de-0691-4a1a-b11b-c591bf866d91"
      },
      "source": [
        "import pickle\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "import math\n",
        "from torch import einsum\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "torch.manual_seed(0)\n",
        "\n",
        "torch.cuda.is_available()\n",
        "\n",
        "if torch.cuda.is_available:\n",
        "  dev = 'cuda:0'\n",
        "else:\n",
        "  dev = 'CPU'\n",
        "\n",
        "device = torch.device(dev)\n",
        "\n",
        "from tqdm import tqdm\n",
        "!pip install tensorly\n",
        "import tensorly as tl\n",
        "tl.set_backend('pytorch')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly\n",
            "  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n",
            "Installing collected packages: nose, tensorly\n",
            "Successfully installed nose-1.3.7 tensorly-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyAwmp7eFo89"
      },
      "source": [
        "def unit(A,B):\n",
        "  return(torch.einsum('ij, ik -> ijk', A,B))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbFQuIwJFyOa"
      },
      "source": [
        "def make_tensor(core_tensors, decompos):\n",
        "  \"\"\"\n",
        "  computes the tensor made up of \"core_tensors\" according to a given tensor decomposition, \"decompos\".\n",
        "  \n",
        "  Parameters\n",
        "  -------\n",
        "  core_tensors: list\n",
        "               list of cores of the corresponding tensor decomposition.\n",
        "  \n",
        "  decomposition: str\n",
        "                the name of a decomposition. Ex, CP, Tucker, TT, etc.\n",
        "  Returns\n",
        "  ------\n",
        "  tensor\n",
        "    Tensor made up of core tensors.\n",
        "  \"\"\"\n",
        "  if decompos == 'TT':\n",
        "    W = tl.tt_to_tensor(core_tensors)\n",
        "  if decompos == 'CP':\n",
        "    rank = core_tensors[0].shape[1]\n",
        "    dev = core_tensors[0].device\n",
        "    W = tl.cp_to_tensor((torch.ones(rank).to(dev),core_tensors))\n",
        "  if decompos == 'HT':\n",
        "    W = ht_to_tensor_top_buttom(core_tensors)\n",
        "  return W"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLsHBEXHFyFX"
      },
      "source": [
        "def inner_product(data_tensor, weight_tensor):\n",
        "  \"\"\"\n",
        "  Computes the inner products  between a batch of tensors and a weight tensor\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "  data_tensor: torch tensor\n",
        "               batch of input tensors of size n x d_1 x ... x d_p\n",
        "  weight_tensor: torch tensor\n",
        "               tensor of order p, the weight tensor of the model.\n",
        "\n",
        "  Returns\n",
        "  ------\n",
        "  vector\n",
        "    Vector of size n containing the inner products \n",
        "  \"\"\"\n",
        "  return torch.matmul(data_tensor.reshape([data_tensor.shape[0],-1]),weight_tensor.ravel())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_p-VFiqFpFr"
      },
      "source": [
        "def ht_to_tensor_top_buttom(core_tensors):\n",
        "  \"\"\"\n",
        "  computes the tensor made up of \"core_tensors\" according to binary hierarchical Tucker decomposition\".\n",
        "  \n",
        "  Parameters\n",
        "  -------\n",
        "  core_tensors: list\n",
        "               list of cores of the HT decomposition in this order: [[root], [[ Level 2], [ Level 3] , .... , [Leaves] ] ]\n",
        "  \n",
        "  Returns\n",
        "  ------\n",
        "  tensor\n",
        "    Tensor made up of core tensors.\n",
        "  \"\"\"\n",
        "  root = core_tensors[0]\n",
        "  interior_levels = core_tensors[1] #interior_levels includes all levels but the first one containing the root.\n",
        "\n",
        "  tree = root[0]\n",
        "  for cores in interior_levels: \n",
        "    num_cores = len(cores)  \n",
        " #   assert num_cores == 2**(l+1), \"!!!!\"\n",
        "    for n in range(0,num_cores,2):\n",
        "      core_1, core_2 = cores[n] , cores[n+1]\n",
        "      tree = torch.einsum('i..., ijk -> ...jk', tree, unit(core_1, core_2))\n",
        "\n",
        "  return tree"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVXHT6V-MTwy"
      },
      "source": [
        "def check(core_tensors):\n",
        "  root = core_tensors[0]\n",
        "  interior_levels = core_tensors[1] #interior_levels includes all levels but the first one containing the root.\n",
        "  level_2 = interior_levels[0]\n",
        "  level_3 = interior_levels[1]\n",
        "  level_4 = interior_levels[2]\n",
        "  tree = root[0]\n",
        "  tree = torch.einsum('i, ijk -> jk', tree, unit(level_2[0], level_2[1]))\n",
        "  tree = torch.einsum('ij, imn, jpq -> mnpq', tree, unit(level_3[0], level_3[1]), unit(level_3[2], level_3[3]))\n",
        "  tree = torch.einsum('ijkl, imn, jpq, kst, lyz -> mnpqstyz', tree, unit(level_4[0], level_4[1]), unit(level_4[2], level_4[3]), unit(level_4[4], level_4[5]), unit(level_4[6], level_4[7]))\n",
        "\n",
        "  return tree"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwmEArN0F9WI"
      },
      "source": [
        "class HTModel_top_buttom(nn.Module):      \n",
        "    \"\"\" \n",
        "    Class for a linear binary classifier parameterized by a (binary) HT tensor.\n",
        "    \"\"\"\n",
        "    def __init__(self, order, dimension, rank, task = 'classification' ,init='normal'): \n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ---------\n",
        "        order: int\n",
        "          order of the tensor, i.e., the number of free legs\n",
        "        dimension: int\n",
        "          Uniform dimension of the HT tensor \n",
        "        rank: int\n",
        "          Uniform rank of the the HT tensor\n",
        "        init: string\n",
        "          initialization method for the core tensors of the HT parameters\n",
        "          choices are \"uniform\" and \"normal\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.order, self.dim, self.bond = order , dimension, rank\n",
        "        self.num_layers = int(math.log(self.order, 2) + 1)\n",
        "\n",
        "        self.weight_root = [nn.Parameter(torch.Tensor(self.bond))]\n",
        "        self.int_layers = [None for i in range(self.num_layers-1)] #This includes all layer but the one containing the root.\n",
        "\n",
        "        self.int_layers[-1] = [nn.Parameter(torch.Tensor( self.bond, self.dim)) for i in range(self.order)] #This gives the leaves of the tree.\n",
        "\n",
        "        for i in range(1,self.num_layers-1):  #This includes all L-2 interior layers.\n",
        "          self.int_layers[i-1] = [nn.Parameter(torch.Tensor(self.bond, self.bond)) for k in range(2**i)]\n",
        "\n",
        "        self.params = nn.ParameterList( self.weight_root + [item for level in self.int_layers for item in level]) \n",
        "\n",
        "        self.nested_weights = [ self.weight_root, self.int_layers] # This variable is defined to have a nested list for doing contractions in forward function.\n",
        "\n",
        "\n",
        "        # initialize weights and biases\n",
        "        for weight in self.params:\n",
        "          if init=='normal':\n",
        "            torch.nn.init.normal_( weight, mean=0.0, std= .5)\n",
        "          elif init=='uniform':\n",
        "            torch.nn.init.uniform_(weight,-1,1)\n",
        "\n",
        "    def forward(self, x): \n",
        "        \"\"\"\n",
        "        Computes the forward pass\n",
        "\n",
        "        Parameters\n",
        "        ---------\n",
        "        self\n",
        "\n",
        "        x: Batches of n input tensors of order [order]\n",
        "            \n",
        "        Returns\n",
        "        ------\n",
        "        (for the classification task) torch tensor of shape [n,2]\n",
        "          Tensor containing the scores of each input for the two classes\n",
        "\n",
        "        (for the regression task) torch tensor of shape[n]\n",
        "          containing the predicted real value of each input data\n",
        "    \n",
        "        \"\"\"\n",
        "        ht_weight = make_tensor(self.nested_weights, 'HT')    #This line refers to the above-defined function 'ht_to_tensor_top_buttom' through the function 'make_tensor'.\n",
        "        prod = inner_product(x, ht_weight)\n",
        "        if task == 'classification':\n",
        "          return torch.stack((prod,-1*prod),0).T  # w times x + b  \n",
        "        if task == 'regression':\n",
        "          return prod#.view(-1,1)     \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdF39TiKXIH"
      },
      "source": [
        "my_ht = HTModel_top_buttom(8,3,2)\n",
        "a = check(my_ht.nested_weights) == ht_to_tensor_top_buttom(my_ht.nested_weights)\n",
        "False in a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebNZ0Vm9F9Mo"
      },
      "source": [
        "class CPModel(nn.Module):      \n",
        "    \"\"\" \n",
        "    Class for a linear binary classifier parameterized by a CP tensor \n",
        "    \"\"\"\n",
        "    def __init__(self, order, dimension, rank, task = 'classification', init='normal'): \n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ---------\n",
        "        order: int\n",
        "          Order of the CP tensor\n",
        "        dimension: int\n",
        "          Uniform dimension of the CP tensor \n",
        "        rank: int\n",
        "          Uniform rank of the the CP tensor\n",
        "        init: string\n",
        "          initialization method for the core tensors of the CP parameters\n",
        "          choices are \"uniform\" and \"normal\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.order, self.dim, self.bond = order, dimension, rank\n",
        "\n",
        "        self.weights = [nn.Parameter(torch.Tensor(self.dim, self.bond)) for i in range(self.order)]\n",
        "\n",
        "        self.params = nn.ParameterList(self.weights)\n",
        "\n",
        "        # initialize weights and biases\n",
        "        for weight in self.params:\n",
        "          if init=='normal':\n",
        "            torch.nn.init.normal_( weight, mean=0.0, std= .5)\n",
        "          elif init=='uniform':\n",
        "            torch.nn.init.uniform_(weight,-1,1)\n",
        "\n",
        "    def forward(self, x): \n",
        "        \"\"\"\n",
        "        Computes the forward pass\n",
        "\n",
        "        Parameters\n",
        "        ---------\n",
        "        self\n",
        "\n",
        "        x: Batches of n input tensors of order [order]\n",
        "            \n",
        "        Returns\n",
        "        ------\n",
        "        (for the classification task) torch tensor of shape [n,2]\n",
        "          Tensor containing the scores of each input for the two classes\n",
        "\n",
        "        (for the regression task) torch tensor of shape[n]\n",
        "          containing the predicted real value of each input data\n",
        "    \n",
        "        \"\"\"\n",
        "        cp_weight = make_tensor(self.weights, 'CP')\n",
        "        prod = inner_product(x, cp_weight)\n",
        "        if task == 'classification':\n",
        "          return torch.stack((prod,-1*prod),0).T  # w times x + b    \n",
        "        if task == 'regression':\n",
        "          return prod#.view(-1,1)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubLR0qFCr9dZ"
      },
      "source": [
        "class TTModel(nn.Module):      \n",
        "    \"\"\" \n",
        "    Class for a linear binary classifier parameterized by a TT tensor \n",
        "    \"\"\"\n",
        "    def __init__(self, order, dimension, rank, task = 'classification', init='normal'): \n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ---------\n",
        "        order: int\n",
        "          Order of the TT tensor\n",
        "        dimension: int\n",
        "          Uniform dimension of the the TT tensor \n",
        "        rank: int\n",
        "          Uniform rank of the the TT tensor\n",
        "        init: string\n",
        "          initialization method for the core tensors of the TT parameters\n",
        "          choices are \"uniform\" and \"normal\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.order, self.dim, self.bond = order, dimension, rank\n",
        "\n",
        "        cores = [None for i in range(self.order)]\n",
        "        self.weights = [None for i in range(self.order)]\n",
        "        cores[0] = torch.Tensor(1,self.dim, self.bond)\n",
        "        for l in range(1,self.order-1):\n",
        "          cores[l] = torch.Tensor(self.bond, self.dim, self.bond)\n",
        "        cores[-1] = torch.Tensor(self.bond, self.dim,1)\n",
        "        for l in range(self.order):\n",
        "          self.weights[l] = nn.Parameter(cores[l])\n",
        "        self.params = nn.ParameterList(self.weights)\n",
        "\n",
        "        # initialize weights and biases\n",
        "        for weight in self.params:\n",
        "          if init=='normal':\n",
        "            torch.nn.init.normal_( weight, mean=0.0, std= .5)\n",
        "          elif init=='uniform':\n",
        "            torch.nn.init.uniform_(weight,-1,1)\n",
        "\n",
        "    def forward(self, x): \n",
        "        \"\"\"\n",
        "        Computes the forward pass\n",
        "\n",
        "        Parameters\n",
        "        ---------\n",
        "        self\n",
        "\n",
        "        x: Batches of n input tensors of order [order]\n",
        "            \n",
        "        Returns\n",
        "        ------\n",
        "        (for the classification task) torch tensor of shape [n,2]\n",
        "          Tensor containing the scores of each input for the two classes\n",
        "\n",
        "        (for the regression task) torch tensor of shape[n]\n",
        "          containing the predicted real value of each input data\n",
        "    \n",
        "        \"\"\"\n",
        "        TT_weight = make_tensor(self.weights, 'TT')\n",
        "        prod = inner_product(x, TT_weight)\n",
        "#        return torch.stack((prod,-1*prod),0).T  # w times x + b       \n",
        "\n",
        "        if task == 'classification':\n",
        "          return torch.stack((prod,-1*prod),0).T  # w times x + b    \n",
        "        if task == 'regression':\n",
        "          return prod#.view(-1,1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First, we define a function to produce the examples.\n",
        "#To make analogy with Cohen et al.'s work, we make the data tensor as a tensor product (rank-1).\n",
        "import string\n",
        "list_of_letters = list(string.ascii_letters)\n",
        "def make_inputs(size, order, dimension):\n",
        "  '''\n",
        "  provides a batch of input tensorial data\n",
        "\n",
        "  Parameters\n",
        "  -----------\n",
        "  size: int\n",
        "        the batch size\n",
        "  order: int\n",
        "         the order of each tensor in the batch\n",
        "  dimension: int\n",
        "         the dimension of the tensor along all its modes \n",
        "\n",
        "  Returns\n",
        "  -----------\n",
        "     a rank-1 tensor of shape [size, dimension, dimension , ...., dimension] (a tensor of order [1+order])\n",
        "     \n",
        "  '''\n",
        "  string_einsum_left =''\n",
        "  string_einsum_right =''\n",
        "\n",
        "  for o in range(order-1):\n",
        "    string_einsum_left += list_of_letters[o]+','\n",
        "    string_einsum_right += list_of_letters[o]\n",
        "\n",
        "  string_einsum_left += list_of_letters[order-1] \n",
        "  string_einsum_right += list_of_letters[order-1] \n",
        "\n",
        "  einsum_prod = string_einsum_left + '->' + string_einsum_right\n",
        "  list_data_tensors = []\n",
        "  for j in range(size):\n",
        "    data_vecs = [torch.randn(dimension) for i in range(order)]\n",
        "    data_tensor = torch.einsum(einsum_prod , data_vecs) #This line outputs a rank-1 tensor of order [order] by doing an einsum operation of type ('i,j,...,k -> ij...k')\n",
        "    list_data_tensors.append(data_tensor)\n",
        "  data = torch.stack(list_data_tensors) #Here, the out put is a tensor of order [order + 1].\n",
        "  return data\n",
        "\n",
        "def make_labels(inputs, oracle, order,dimension,target_rank, task, init):\n",
        "  '''\n",
        "  provides a batch of labels.\n",
        "\n",
        "  Parameters:\n",
        "  ------------\n",
        "  inputs: tensor of shape [batch_size, dimension, ... ,dimension] of order [order+1]\n",
        "\n",
        "  oracle: string\n",
        "          the name of the target model which is a tensor network (either CP, or TT, or HT)\n",
        "\n",
        "  order: int\n",
        "         the order of the tensors in the variable 'inputs' which should be less than the order of 'inputs' by 1. (inputs is a batch of tensors)\n",
        " \n",
        "  dimension: int\n",
        "         the dimension of the tensors in inputs along the modes\n",
        "\n",
        "  target_rank: int\n",
        "         the rank of the oracle, which is a tensor network.\n",
        "\n",
        "  task: string\n",
        "         either classification, or regression\n",
        "\n",
        "  init: string\n",
        "        the initialization of the parameters of the oracle tensor network (either 'uniform' or 'normal')\n",
        "\n",
        "\n",
        "  Returns:\n",
        "  ------------\n",
        "      a tensor of size [batch_size] containing the labels assigned to the variable 'inputs' according to the oracle.\n",
        "  '''\n",
        "  #First, do some dimension checks, the dimensionality of inputs should match the function variables, order and dimension!\n",
        "  if len(inputs.shape) != (order + 1) or inputs.shape[1] != dimension:\n",
        "    print('Model dimension not compatible with the input size!')\n",
        "  if oracle == 'HT':\n",
        "    target_model = HTModel_top_buttom(order,dimension,target_rank,task = task,init='normal')\n",
        "  if oracle == 'CP':\n",
        "    target_model = CPModel(order,dimension,target_rank, task = task, init='normal')\n",
        "  if oracle == 'TT':\n",
        "    target_model = TTModel(order,dimension,target_rank, task = task, init='normal')\n",
        " # test_inputs = make_inputs(test_size, order, dimension)#torch.randn([test_size] + [dimension]*order)\n",
        "  if task == 'classification':\n",
        "    _,test_labels = torch.max(target_model.forward(inputs),axis=1)\n",
        "  if task == 'regression':\n",
        "    test_labels = target_model.forward(inputs).detach_() #.detach_() added to fix an error with the computational graph.\n",
        "  return test_labels\n",
        "\n",
        "# train = data_utils.TensorDataset(test_inputs, test_labels)\n",
        "\n",
        "def make_dataset(inputs, labels):\n",
        "  '''\n",
        "  provides a torch dataset\n",
        "\n",
        "  Parameters:\n",
        "  ----------\n",
        "\n",
        "  inputs: torch tensor\n",
        "       a tensor of shape [batch_size, dimension, ... ,dimension]\n",
        "\n",
        "\n",
        "  labels: torch tensor\n",
        "       a tensor of shape [batch_size]\n",
        "  Returns:\n",
        "  ------------\n",
        "  a torch dataset with inputs as features and labels as their corresponding labels.\n",
        "  '''\n",
        "  if inputs.shape[0] != labels.shape[0]:\n",
        "    print('inputs and labels of inconsistent size!')\n",
        "  return data_utils.TensorDataset(inputs,labels)"
      ],
      "metadata": {
        "id": "Eqn4T6kyvhoL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TNlearner():\n",
        "  def __init__(self, batch_size, order, dimension, oracle, target_rank, init, device , seed):\n",
        "    self.batch_size, self.order, self.dimension, self.target_rank, self.oracle, self.task, self.init = batch_size, order, dimension, target_rank,oracle,task,init\n",
        "    self.device = device\n",
        "    self.seed = seed\n",
        "  def data_loader(self,size):\n",
        "    torch.manual_seed(seed) #Is this a good idea to produce same samplesfor the same oracle?\n",
        "    train_input = make_inputs(size, self.order, self.dimension)\n",
        "    train_label = make_labels(train_input, self.oracle , self.order, self.dimension, self.target_rank, self.task , self.init)\n",
        "    self.train_dataset = make_dataset(train_input, train_label)\n",
        "    return data_utils.DataLoader(self.train_dataset, self.batch_size, shuffle=True)    \n",
        "\n",
        "  def make_loaders(self, sample_size, test_size):\n",
        "    train_loader = self.data_loader(sample_size)\n",
        "    test_loader = self.data_loader(test_size)    \n",
        "    return {'train': train_loader, 'valid':test_loader}\n",
        "\n",
        "  def train_model(self, sample_size, test_size, model_rank, optimizer, lr, epochs, model_name, every_n_epochs , epochs_saved = False , init_model='normal'): #Delete loss_func!\n",
        "    \"\"\"\n",
        "    Trains a TT or HT or CP classifier and returns the trained model.\n",
        "\n",
        "    Parameters\n",
        "    --------\n",
        "    sample_size: int\n",
        "          training sample size\n",
        "    \n",
        "    test_size: int\n",
        "          test sample size\n",
        "\n",
        "    data_loaders: dict of two dataloaders, with keys 'train' and 'valid'. dataloaders = {'train':training_data, 'valid': valid_data}\n",
        "                  \n",
        "    model_rank: int\n",
        "          the model's rank\n",
        "    optimizer:\n",
        "          pytorch optimizer \n",
        "    lr: float\n",
        "          learning rate\n",
        "    epochs: int\n",
        "          number of learning epochs\n",
        "    model_name: str\n",
        "          the name of the tensor decomposition model, Eg., CP, TT, etc\n",
        "    every_n_epochs: int\n",
        "          at what number of epochs to save results?\n",
        "    epochs_saved: Boolean\n",
        "          Whether or not to save the training losses over epochs, we put it True, if we are concerned with the convergence of the loss plots.\n",
        "    init: str\n",
        "          which initialization we take for the weights of the to-be-trained model.\n",
        "    Returns\n",
        "    ------\n",
        "      Trained model\n",
        "        \n",
        "    \"\"\"\n",
        "    data_loader = self.make_loaders(sample_size, test_size)\n",
        "    train_losses = []\n",
        "    train_accs=[]\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    dict_res = {'losses':{'train': train_losses, 'valid':test_losses}, 'accuracies': {'train':train_accs, 'valid': test_accs} }\n",
        "    num_samples = {'train': sample_size, 'valid': test_size}\n",
        "    num_samples = {'train': 500, 'valid': 200}\n",
        "    if model_name == 'TT':\n",
        "      model = TTModel(self.order, self.dimension, model_rank, self.task, init= init_model)#.to(device) Note that before, I had forgotten to write \"task\" as an argument for TTModel, CPModel and HTModel.\n",
        "    if model_name == 'CP':\n",
        "      model = CPModel(self.order, self.dimension, model_rank, self.task, init= init_model)#.to(device)\n",
        "    if model_name == 'HT':\n",
        "      model = HTModel_top_buttom(self.order, self.dimension, model_rank, self.task, init= init)#.to(device)\n",
        "    model = model.to(self.device)\n",
        "    if self.task == 'classification':\n",
        "      loss_func = nn.CrossEntropyLoss()\n",
        "    if self.task == 'regression':\n",
        "      loss_func = nn.MSELoss()\n",
        "    optimizer = optimizer(model.parameters(), lr)\n",
        "    for e in range(epochs):  \n",
        "      for mode in ['train','valid']:\n",
        "        loss_epoch = 0\n",
        "        acc_epoch = 0     \n",
        "        if mode == 'train':\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "        for data, label in data_loader[mode]:\n",
        "          data = data.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "          model_output = model.forward(data)#.detach_() #Meraj's trick\n",
        "          loss = loss_func(model_output, label)\n",
        "\n",
        "          if self.task == 'classification':\n",
        "            pred = torch.argmax(model_output, axis = 1)\n",
        "            acc = torch.sum((pred == label).float())\n",
        "            acc_epoch += acc/num_samples[mode]\n",
        "\n",
        "          loss_epoch += loss\n",
        "          if mode == 'train':\n",
        "            loss.backward()#(retain_graph= True)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        if epochs_saved == True and e%every_n_epochs == 0:\n",
        "          dict_res['losses'][mode].append(loss_epoch)\n",
        "          if self.task == 'classification':\n",
        "            dict_res['accuracies'][mode].append(acc_epoch)\n",
        "    results = {'trained_model': model, #'train_loss': train_losses, 'train_acc': train_accs, 'test:loss': test_losses, 'test_acc': test_accs, \n",
        "                    'model_params':{'rank':model_rank, 'loss_func':loss_func, 'optimizer':optimizer, 'lr':lr, 'epochs':epochs, 'model_name':model_name, 'task':self.task, 'init':init}}\n",
        "\n",
        "    return (results, dict_res) #epoch_losses to add\n"
      ],
      "metadata": {
        "id": "70ahlqUW1VJq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_res = {'CP' : {}, 'HT': {}}"
      ],
      "metadata": {
        "id": "nLiv3Gc7ERt3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=500\n",
        "batch_size = 10\n",
        "test_size = 200\n",
        "lr = .00001\n",
        "epochs= 300\n",
        "task = 'regression'\n",
        "dimension = 4\n",
        "order = 4\n",
        "target_rank = 8\n",
        "model_rank = 6\n",
        "oracle ='CP'\n",
        "init = 'uniform'\n",
        "device = 'cuda:0'\n",
        "model_name_list= ['HT','CP']\n",
        "rank_list = [2,4,6,8]\n",
        "seed = 0\n",
        "TNclass= TNlearner(batch_size, order, dimension, oracle, target_rank, init, device, seed)\n",
        "for model_name in model_name_list:\n",
        "  for model_rank in rank_list:\n",
        "    _, dict_res[model_name][model_rank] = TNclass.train_model(train_size, test_size, model_rank, optim.SGD, lr , epochs, model_name, every_n_epochs= 10, epochs_saved=True, init_model='uniform')"
      ],
      "metadata": {
        "id": "ScvEfduAPREM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of final epoch's loss for model HT\n",
        "modes = ['train', 'valid']\n",
        "loss_list_rank = {'CP': {'train' : None , 'valid': None}  , 'HT': {'train' :None  , 'valid':None } }\n",
        "for model in model_name_list:\n",
        "  for mode in modes:\n",
        "    loss_list_rank[model][mode] =  [ dict_res[model][model_rank]['losses'][mode][-1].cpu().detach().numpy() for model_rank in rank_list]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(1,3):\n",
        "  plt.subplot(1,2,i)\n",
        "  plt.plot(rank_list, loss_list_rank['HT'][modes[i-1]], label = 'HT')\n",
        "  plt.plot(rank_list, loss_list_rank['CP'][modes[i-1]], label = 'CP')\n",
        "  plt.legend()\n",
        "  plt.xlabel('model rank')\n",
        "  plt.ylabel(f'{modes[i-1]} loss')\n",
        "  plt.title(f'oracle is {oracle}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Jn-0qvgqQXjK",
        "outputId": "496c3af0-0a6f-4d8e-dedc-877a9445eb34"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From here on, under construction."
      ],
      "metadata": {
        "id": "2sU5EpRqUgJT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KUlYpbPwqlk"
      },
      "source": [
        "##To experiment with HT vs. CP:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYlBYXDBSdLv"
      },
      "source": [
        "__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3tqSpPylp1t"
      },
      "source": [
        "def plot_regression_CP_vs_HT(results_CP, results_HT, train_sample_sizes,  oracle, target_rank, ranks, learning_rate, n_runs):\n",
        "  train_loss_CP = {}\n",
        "  train_loss_HT = {}\n",
        "  test_loss_CP = {}\n",
        "  test_loss_HT = {}\n",
        "  gen_gaps_CP = {}\n",
        "  gen_gaps_HT = {}\n",
        "  with sns.axes_style('darkgrid'):\n",
        "    colors = sns.color_palette('husl' , 2)\n",
        "    figure = plt.figure(figsize=(20, 4))\n",
        "    c = 0\n",
        "    for sample_size in train_sample_sizes:\n",
        "      #First, training loss\n",
        "      train_loss_CP[sample_size] = np.array([[((losses[1]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_tr_loss_CP = np.mean(train_loss_CP[sample_size], axis = 0) \n",
        "      stds_tr_loss_CP = np.std(train_loss_CP[sample_size], axis = 0)\n",
        "\n",
        "      train_loss_HT[sample_size] = np.array([[((losses[1]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_tr_loss_HT = np.mean(train_loss_HT[sample_size], axis = 0) \n",
        "      stds_tr_loss_HT = np.std(train_loss_HT[sample_size], axis = 0)\n",
        "      plt.xlabel('rank')\n",
        "      plt.subplot(1, 3, 1)\n",
        "      plt.title(f'target model = {oracle} with rank {target_rank}, lr = {learning_rate}')\n",
        "\n",
        "      plt.ylabel('training loss')\n",
        "    # plt.yscale('log')\n",
        "      plt.plot(ranks, ys_tr_loss_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_tr_loss_CP) - torch.tensor(stds_tr_loss_HT)) , list(torch.tensor(ys_tr_loss_CP) + torch.tensor(stds_tr_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "  #   plt.plot(ranks,list(torch.tensor(upper_bound[sample_size])), color = colors[c] , linestyle ='dashed', label='_nolegend_') # The factor 1/4 is to reduce the distance between the bound curve from the theory and the one from our experiment.\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_tr_loss_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_tr_loss_HT) - torch.tensor(stds_tr_loss_HT)) , list(torch.tensor(ys_tr_loss_HT) + torch.tensor(stds_tr_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()\n",
        "\n",
        "    #Secondly, test loss.\n",
        "  \n",
        "      test_loss_CP[sample_size] = np.array([[((losses[2]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_test_loss_CP = np.mean(test_loss_CP[sample_size], axis = 0) \n",
        "      stds_test_loss_CP = np.std(test_loss_CP[sample_size], axis = 0)\n",
        "\n",
        "      test_loss_HT[sample_size] = np.array([[((losses[2]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_test_loss_HT = np.mean(test_loss_HT[sample_size], axis = 0) \n",
        "      stds_test_loss_HT = np.std(test_loss_HT[sample_size], axis = 0)\n",
        "      plt.subplot(1, 3, 2)\n",
        "\n",
        "      plt.title(f'n = {train_sample_sizes[0]}, #run = {n_runs}')\n",
        "\n",
        "      plt.ylabel('test loss')\n",
        "    #  plt.yscale('log')\n",
        "      plt.plot(ranks, ys_test_loss_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_loss_CP) - torch.tensor(stds_test_loss_CP)) , list(torch.tensor(ys_test_loss_CP) + torch.tensor(stds_test_loss_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_test_loss_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_loss_HT) - torch.tensor(stds_test_loss_HT)) , list(torch.tensor(ys_test_loss_HT) + torch.tensor(stds_test_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()\n",
        "\n",
        "      # Third, generalization error.\n",
        "      gen_gaps_CP[sample_size] = np.array([[((losses[2] - losses[1]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_gen_CP = np.mean(gen_gaps_CP[sample_size], axis = 0) \n",
        "      stds_gen_CP = np.std(gen_gaps_CP[sample_size], axis = 0)\n",
        "\n",
        "      gen_gaps_HT[sample_size] = np.array([[((losses[2] - losses[1]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      # n_params = order*dimension\n",
        "      # upper_bound[sample_size] = np.array( [2*(np.sqrt( n_params*rank**2*math.log(8*sample_size*order*np.e / (n_params*rank**2))/sample_size))  for rank in ranks])\n",
        "      ys_gen_HT = np.mean(gen_gaps_HT[sample_size], axis = 0) \n",
        "      stds_gen_HT = np.std(gen_gaps_HT[sample_size], axis = 0)\n",
        "      \n",
        "      plt.subplot(1,3,3)\n",
        "\n",
        "      plt.title(f'number of epochs = {epochs}')\n",
        "      plt.ylabel('generalization error')\n",
        "    #  plt.yscale('log')\n",
        "      plt.plot(ranks, ys_gen_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_gen_CP) - torch.tensor(stds_gen_CP)) , list(torch.tensor(ys_gen_CP) + torch.tensor(stds_gen_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "  #   plt.plot(ranks,list(torch.tensor(upper_bound[sample_size])), color = colors[c] , linestyle ='dashed', label='_nolegend_') # The factor 1/4 is to reduce the distance between the bound curve from the theory and the one from our experiment.\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_gen_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_gen_HT) - torch.tensor(stds_gen_HT)) , list(torch.tensor(ys_gen_HT) + torch.tensor(stds_gen_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "\n",
        "      plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8VKzl8tWKXd"
      },
      "source": [
        "def plot_CP_vs_HT(results_CP, results_HT, train_sample_sizes,  oracle, target_rank, ranks, learning_rate):\n",
        "\n",
        "  train_loss_CP = {}\n",
        "  train_loss_HT = {}\n",
        "  test_loss_CP = {}\n",
        "  test_loss_HT = {}\n",
        "  gen_gaps_CP = {}\n",
        "  gen_gaps_HT = {}\n",
        "  test_acc_CP = {}\n",
        "  test_acc_HT = {}\n",
        "  train_acc_CP = {}\n",
        "  train_acc_HT = {}\n",
        "  with sns.axes_style('darkgrid'):\n",
        "    colors = sns.color_palette('husl' , 2)\n",
        "    figure = plt.figure(figsize=(20, 4))\n",
        "    c = 0\n",
        "    for sample_size in train_sample_sizes:\n",
        "      #First, training loss\n",
        "      train_loss_CP[sample_size] = np.array([[((losses[1]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_tr_loss_CP = np.mean(train_loss_CP[sample_size], axis = 0) \n",
        "      stds_tr_loss_CP = np.std(train_loss_CP[sample_size], axis = 0)\n",
        "\n",
        "      train_loss_HT[sample_size] = np.array([[((losses[1]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_tr_loss_HT = np.mean(train_loss_HT[sample_size], axis = 0) \n",
        "      stds_tr_loss_HT = np.std(train_loss_HT[sample_size], axis = 0)\n",
        "      plt.xlabel('rank')\n",
        "      plt.subplot(1, 5, 1)\n",
        "      plt.title(f'target model = {oracle} with rank {target_rank}, , lr = {learning_rate}')\n",
        "\n",
        "      plt.ylabel('training loss')\n",
        "    # plt.yscale('log')\n",
        "      plt.plot(ranks, ys_tr_loss_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_tr_loss_CP) - torch.tensor(stds_tr_loss_HT)) , list(torch.tensor(ys_tr_loss_CP) + torch.tensor(stds_tr_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "  #   plt.plot(ranks,list(torch.tensor(upper_bound[sample_size])), color = colors[c] , linestyle ='dashed', label='_nolegend_') # The factor 1/4 is to reduce the distance between the bound curve from the theory and the one from our experiment.\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_tr_loss_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_tr_loss_HT) - torch.tensor(stds_tr_loss_HT)) , list(torch.tensor(ys_tr_loss_HT) + torch.tensor(stds_tr_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()\n",
        "\n",
        "    #Secondly, test loss.\n",
        "  \n",
        "      test_loss_CP[sample_size] = np.array([[((losses[2]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_test_loss_CP = np.mean(test_loss_CP[sample_size], axis = 0) \n",
        "      stds_test_loss_CP = np.std(test_loss_CP[sample_size], axis = 0)\n",
        "\n",
        "      test_loss_HT[sample_size] = np.array([[((losses[2]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_test_loss_HT = np.mean(test_loss_HT[sample_size], axis = 0) \n",
        "      stds_test_loss_HT = np.std(test_loss_HT[sample_size], axis = 0)\n",
        "      plt.subplot(1, 5, 2)\n",
        "\n",
        "      plt.title(f'n = {train_sample_sizes[0]}')\n",
        "\n",
        "      plt.ylabel('test loss')\n",
        "    #  plt.yscale('log')\n",
        "      plt.plot(ranks, ys_test_loss_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_loss_CP) - torch.tensor(stds_test_loss_CP)) , list(torch.tensor(ys_test_loss_CP) + torch.tensor(stds_test_loss_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_test_loss_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_loss_HT) - torch.tensor(stds_test_loss_HT)) , list(torch.tensor(ys_test_loss_HT) + torch.tensor(stds_test_loss_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()\n",
        "\n",
        "      #Third, test accuracy.\n",
        "\n",
        "      test_acc_CP[sample_size] = np.array([[((losses[3]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_test_acc_CP = np.mean(test_acc_CP[sample_size], axis = 0) \n",
        "      stds_test_acc_CP = np.std(test_acc_CP[sample_size], axis = 0)\n",
        "\n",
        "      test_acc_HT[sample_size] = np.array([[((losses[3]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_test_acc_HT = np.mean(test_acc_HT[sample_size], axis = 0) \n",
        "      stds_test_acc_HT = np.std(test_acc_HT[sample_size], axis = 0)\n",
        "      plt.subplot(1, 5, 3)\n",
        "      plt.title(f'order = {order}, dimension = {dimension}')\n",
        "\n",
        "      plt.xlabel('rank')\n",
        "      plt.ylabel('test accuracy')\n",
        "      plt.yscale('log')\n",
        "      plt.plot(ranks, ys_test_acc_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_acc_CP) - torch.tensor(stds_test_acc_CP)) , list(torch.tensor(ys_test_acc_CP) + torch.tensor(stds_test_acc_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_test_acc_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_test_acc_HT) - torch.tensor(stds_test_acc_HT)) , list(torch.tensor(ys_test_acc_HT) + torch.tensor(stds_test_acc_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()\n",
        "      #Fourth, train accuracy.\n",
        "\n",
        "      train_acc_CP[sample_size] = np.array([[((losses[4]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_train_acc_CP = np.mean(train_acc_CP[sample_size], axis = 0) \n",
        "      stds_train_acc_CP = np.std(train_acc_CP[sample_size], axis = 0)\n",
        "\n",
        "      train_acc_HT[sample_size] = np.array([[((losses[4]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      ys_train_acc_HT = np.mean(train_acc_HT[sample_size], axis = 0) \n",
        "      stds_train_acc_HT = np.std(train_acc_HT[sample_size], axis = 0)\n",
        "      plt.subplot(1, 5, 4)\n",
        "      plt.title(f'test size = {test_size}')\n",
        "\n",
        "      plt.xlabel('rank')\n",
        "      plt.ylabel('train accuracy')\n",
        "      plt.yscale('log')\n",
        "      plt.plot(ranks, ys_train_acc_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_train_acc_CP) - torch.tensor(stds_train_acc_CP)) , list(torch.tensor(ys_train_acc_CP) + torch.tensor(stds_train_acc_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_train_acc_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_train_acc_HT) - torch.tensor(stds_train_acc_HT)) , list(torch.tensor(ys_train_acc_HT) + torch.tensor(stds_train_acc_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "      plt.legend()  \n",
        "          \n",
        "      # Fifth, generalization error.\n",
        "\n",
        "      gen_gaps_CP[sample_size] = np.array([[((losses[2] - losses[1]).detach()) for losses in result[sample_size]] for result in results_CP])\n",
        "      ys_gen_CP = np.mean(gen_gaps_CP[sample_size], axis = 0) \n",
        "      stds_gen_CP = np.std(gen_gaps_CP[sample_size], axis = 0)\n",
        "\n",
        "      gen_gaps_HT[sample_size] = np.array([[((losses[2] - losses[1]).detach()) for losses in result[sample_size]] for result in results_HT])\n",
        "      # n_params = order*dimension\n",
        "      # upper_bound[sample_size] = np.array( [2*(np.sqrt( n_params*rank**2*math.log(8*sample_size*order*np.e / (n_params*rank**2))/sample_size))  for rank in ranks])\n",
        "      ys_gen_HT = np.mean(gen_gaps_HT[sample_size], axis = 0) \n",
        "      stds_gen_HT = np.std(gen_gaps_HT[sample_size], axis = 0)\n",
        "      \n",
        "      plt.subplot(1,5,5)\n",
        "\n",
        "      plt.title(f'number of epochs = {epochs}')\n",
        "      plt.ylabel('generalization error')\n",
        "    #  plt.yscale('log')\n",
        "      plt.plot(ranks, ys_gen_CP, color = colors[c]  , label ='CP')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_gen_CP) - torch.tensor(stds_gen_CP)) , list(torch.tensor(ys_gen_CP) + torch.tensor(stds_gen_CP)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "  #   plt.plot(ranks,list(torch.tensor(upper_bound[sample_size])), color = colors[c] , linestyle ='dashed', label='_nolegend_') # The factor 1/4 is to reduce the distance between the bound curve from the theory and the one from our experiment.\n",
        "      c+=1\n",
        "      plt.plot(ranks, ys_gen_HT, color = colors[c]  , label ='HT')\n",
        "      plt.fill_between(ranks, list(torch.tensor(ys_gen_HT) - torch.tensor(stds_gen_HT)) , list(torch.tensor(ys_gen_HT) + torch.tensor(stds_gen_HT)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "      c-=1\n",
        "      plt.tight_layout()\n",
        "\n",
        "      plt.legend()\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "650DaIwzyNl9"
      },
      "source": [
        "##The experiment in our paper:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyLyDKx4wp-Z"
      },
      "source": [
        "dimension = 4\n",
        "order = 4\n",
        "target_rank = 8\n",
        "test_size = 4000\n",
        "n_runs = 20\n",
        "train_sample_sizes = [2000, 4000]\n",
        "ranks = [2, 4, 6 , 8 , 10, 12, 14]\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD\n",
        "\n",
        "target_model = HTModel(order,dimension,target_rank,init='uniform')\n",
        "test_inputs = torch.randn([test_size] + [dimension]*order)\n",
        "test_labels = torch.argmax(target_model.forward(test_inputs),axis=1)\n",
        "\n",
        "\n",
        "results = []\n",
        "for n in range(n_runs):\n",
        "  result = {}\n",
        "  for sample_size in train_sample_sizes:\n",
        "    result[sample_size] = []\n",
        "    for rank in ranks:\n",
        "      # generate training data\n",
        "      inputs = torch.randn([sample_size] + [dimension]*order)\n",
        "      labels = torch.argmax(target_model.forward(inputs), axis = 1)\n",
        "      # train the model\n",
        "      model = train_TT_model((inputs, labels), rank, loss, optimizer, lr=learning_rate, epochs=epochs)\n",
        "      test_loss = loss(model.forward(test_inputs), test_labels)\n",
        "      train_loss = loss(model.forward(inputs), labels)\n",
        "      result[sample_size].append((sample_size,train_loss,test_loss))\n",
        "  results.append(result)        \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0kOpOEKTmA7"
      },
      "source": [
        "### Plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "D1LEDNS3eSsZ",
        "outputId": "0d83366c-d702-4e0b-e44f-2451680d8020"
      },
      "source": [
        "log_gen_gaps = {}\n",
        "upper_bound = {}\n",
        "with sns.axes_style('darkgrid'):\n",
        "  colors = sns.color_palette('husl' , 2)\n",
        "  figure = plt.figure(figsize=(4,2.3))\n",
        "  c = 0\n",
        "  for sample_size in train_sample_sizes:\n",
        "    log_gen_gaps[sample_size] = np.array([[((losses[2]-losses[1]).detach()) for losses in result[sample_size]] for result in results])\n",
        "    n_params = order*dimension\n",
        "    upper_bound[sample_size] = np.array( [2*(np.sqrt( n_params*rank**2*math.log(8*sample_size*order*np.e / (n_params*rank**2))/sample_size))  for rank in ranks])\n",
        "    ys = np.mean(log_gen_gaps[sample_size], axis = 0) \n",
        "    stds = np.std(log_gen_gaps[sample_size], axis = 0)\n",
        "    print(ys)\n",
        "    plt.xlabel('rank')\n",
        "    plt.ylabel('generalization')\n",
        "    plt.yscale('log')\n",
        "    plt.plot(ranks, ys, color = colors[c]  , label ='experiment')\n",
        "    plt.fill_between(ranks, list(torch.tensor(ys) - torch.tensor(stds)) , list(torch.tensor(ys) + torch.tensor(stds)), alpha = .3, facecolor = colors[c], label='_nolegend_')\n",
        "    plt.plot(ranks,list(torch.tensor(upper_bound[sample_size])), color = colors[c] , linestyle ='dashed', label='_nolegend_') # The factor 1/4 is to reduce the distance between the bound curve from the theory and the one from our experiment.\n",
        "    c+=1\n",
        "    plt.tight_layout()\n",
        "\n",
        "  plt.legend(\"n=2000 n=4000\".split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00640478 0.02303103 0.03646769 0.05027365 0.07151561 0.08757969\n",
            " 0.10857521]\n",
            "[0.00557374 0.01454905 0.01445679 0.02332144 0.02879337 0.03536797\n",
            " 0.03862754]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x165.6 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    }
  ]
}